<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MIMOSA: Human-AI Co-Creation of Computational Spatial Audio Effects on Videos</title>
  <link rel="icon" type="image/x-icon" href="images/nd.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MIMOSA: Human-AI Co-Creation of Computational Spatial Audio Effects
              on Videos</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://zning.co/" target="_blank">Zheng Ning</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://zhengzhang.me/" target="_blank">Zheng Zhang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://jerrickban.com/" target="_blank">Jerrick Ban</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="" target="_blank">Kaiwen Jiang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="" target="_blank">Ruohong Gan</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://www.yapengtian.com/" target="_blank">Yapeng Tian</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="https://toby.li/" target="_blank">Toby Jia-Jun Li</a><sup>1</sup>,</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup> University of Notre Dame</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>2</sup> University of California, San Diego</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>3</sup> Carnegie Mellon University</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>4</sup> The University of Texas at Dallas</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>
            <br />
            <div class="teaser">
              <img src="static/images/mimosa_teaser.png" alt="The figure shows MIMOSA's human-in-the-loop" />
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://dl.acm.org/doi/10.1145/3635636.3656189" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-acmdl"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <!-- <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2404.15107" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa-regular fa-chalkboard"></i>
                    </span>
                    <span>Slides</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/videos/banner_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat
          pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Spatial audio offers more immersive video consumption experiences to viewers; however,
              creating and editing spatial audio often expensive and requires specialized equipment and skills,
              posing a high barrier for amateur video creators. We present MIMOSA, a human-AI co-creation tool that
              enables amateur users to computationally generate and manipulate spatial audio effects. For a video with
              only monaural or stereo audio, MIMOSA automatically grounds each sound source to the corresponding
              sounding object
              in the visual scene and enables users to further validate and fix the errors in the
              locations of sounding objects. Users can also augment the spatial audio effect by flexibly manipulating
              the sounding source positions and creatively customizing the audio effect. The design of MIMOSA
              exemplifies a human-AI
              collaboration approach that, instead of utilizing state-of art end-to-end "black-box" ML models, uses a
              multistep pipeline
              that aligns its interpretable intermediate results with the user's workflow. A lab user study with 15
              participants
              demonstrates MIMOSA's usability, usefulness, expressiveness, and capability in creating immersive spatial
              audio
              effects in collaboration with users.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Image carousel -->
  <!-- <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/carousel1.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              First image description.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/carousel2.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Second image description.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Third image description.
            </h2>
          </div>
          <div class="item">
            <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Fourth image description.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section> -->
  <!-- End image carousel -->


  <section class="hero is-small">
    <div class="hero-body">
        <div class="container is-three-quarters">
            <h2 class="title is-3">üîß Repair the errors in the model-generated effects</h2>
            <div class="columns" style="width: 80%; margin: auto;">
                <div class="column is-one-third" >
                    <p style="font-size: 1.25em;">Users can simply drag the colored overlays and make them overlapped with the actual sounding position 
                      of the object to fix the error in 2D positions of the sounding objects.
                    </p>
                </div>
                <div class="column is-two-thirds">
                    <div class="item">
                        <video poster="" id="video4" controls muted loop autoplay width="100%">
                            <!-- Your video file here -->
                            <source src="static/videos/fix_2d.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
            <div class="columns" style="width: 80%; margin: auto;">
                <div class="column is-one-third">
                    <p style="font-size: 1.25em;">If the user wants to further fix the depth error, they can move the Z-axis of
                        the sounding object in the 3D object manipulation panel.
                    </p>
                </div>
                <div class="column is-two-thirds">
                    <div class="item">
                        <video poster="" id="video5" controls muted loop autoplay width="100%">
                            <!-- Your video file here -->
                            <source src="static/videos/fix_3d.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>



  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">üé® Creatively augment the spatial audio effects</h2>
        <div class="columns" style="width: 80%; margin: auto;">
          <div class="column is-one-third" >
            <p style="font-size: 1.25em;">Users are able to augment existing audio effect by increasing the relative
              distance among sounding objects using the sound source overlays.
            </p>
          </div>
          <div class="column is-two-thirds" >
            <div class="item">
              <img src="static/images/cre-augment-2d.gif" />
            </div>
            <!-- <p>1. Overlay the colored dots with the sounding objects</p> -->
          </div>
        </div>
        <div class="columns" style="width: 80%; margin: auto;">
          <div class="column is-one-third" >
            <p style="font-size: 1.25em;">In the 3D coordinate, users are able to Adjusting the relative position of the sounding objects
              and the referencing point; move the referencing point and change the moving mode.
            </p>
          </div>
          <div class="column is-two-thirds" >
            <div class="item">
              <video poster="" id="video4" controls muted loop autoplay width="100%">
                <!-- Your video file here -->
                <source src="static/videos/cre_3d.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <div class="columns" style="width: 80%; margin: auto;">
          <div class="column is-one-third" >
            <p style="font-size: 1.25em;">Any change made in either panel will automatically trigger the change in other
              panels to reduce the mental load from the user.
            </p>
          </div>
          <div class="column is-two-thirds" >
            <div class="item">
              <video poster="" id="video4" controls muted loop autoplay width="100%">
                <!-- Your video file here -->
                <source src="static/videos/cre-sync.mp4" type="video/mp4">
              </video>
            </div>
            <!-- <p>1. Overlay the colored dots with the sounding objects</p> -->
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">üïπÔ∏è Technical pipeline</h2>
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <div class="item">
              <img src="static/images/technical_pipl.png"
                alt="The figure shows MIMOSA's human-in-the-loop audiovisual spatialization pipeline. The 3D position of the sounding object is acquired by a set of computer vision models and an audio tagging model telling which object is making the sound. The independent soundtrack of each sounding object is separated from the original soundtrack." />
            </div>
            <br>
            <p style="font-size: 1.25em;">MIMOSA's human-AI collaborative audio spatialization pipeline. Users can validate and adjust the
              intermediate results in three ways. From left to right, 1: users can adjust the audio properties of each
              separated soundtrack; 2: users can manually fix the error in aligning the separated soundtrack to the
              visual object in the video; 3: users can customize the spatial effect for each sounding object by
              manipulating its corresponding visual position.</p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">üëæ Integration with professional video editing tools</h2>
        <div class="columns" style="width: 85%; margin: auto;">
          <div class="column is-one-third" >
            <p style="font-size: 1.25em;">To improve the usability of MIMOSA, we implemented an extension in Adobe Premiere Pro to integrate MIMOSA into the regular workflow of video
              creators. Users can directly import their video projects and edit the spatial audio effects in the same interface.</p>
              <br>
              <img src="static/images/pr_mimosa.png" alt="The figure shows MIMOSA's human-in-the-loop" style="width: 80%; margin: auto;"/>
            </p>
          </div>
          <div class="column is-two-thirds" >
            <div class="item">
              <video poster="" id="video2" controls muted loop autoplay width="100%">
                <!-- Your video file here -->
                <source src="static/videos/mimosa_pr.mp4" type="video/mp4">
              </video>
            </div>
            <!-- <p>1. Overlay the colored dots with the sounding objects</p> -->
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Video carousel -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">üéß Video demos (would recommend watch with headphones)</h2>
        <div id="results-carousel" class="carousel is-half results-carousel">
          <div class="item item-video2">
            <video poster="" id="video2" controls loop width="100%">
              <!-- Your video file here -->
              <source src="static/videos/demo_2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video1">
            <video poster="" id="video1" controls loop width="100%">
              <!-- Your video file here -->
              <source src="static/videos/demo_1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" controls loop width="100%">\
              <!-- Your video file here -->
              <source src="static/videos/demo_3.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video4">
            <video poster="" id="video4" controls loop width="100%">\
              <!-- Your video file here -->
              <source src="static/videos/demo_4.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->






  <!-- Paper poster -->
  <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section> -->
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{ning2024mimosa,
          author = {Ning, Zheng and Zhang, Zheng and Ban, Jerrick and Jiang, Kaiwen and Gan, Ruohong and Tian, Yapeng and Li, Toby Jia-Jun},
          title = {MIMOSA: Human-AI Co-Creation of Computational Spatial Audio Effects on Videos},
          year = {2024},
          isbn = {9798400704857},
          publisher = {Association for Computing Machinery},
          address = {New York, NY, USA},
          url = {https://doi.org/10.1145/3635636.3656189},
          doi = {10.1145/3635636.3656189},
          booktitle = {Creativity and Cognition},
          pages = {156-169},
          numpages = {14},
          keywords = {creator tools, multimodal, sound effects, video},
          location = {Chicago, IL, USA},
          series = {C&C '24}
          }
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a
                href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>